README file for Programming Assignment 3 (C++ edition)
======================================================

Your directory should now contain the following files:

 Makefile		  -> [course dir]/src/PA3/Makefile
 README
 cool.y
 bad.cl
 good.cl
 cool-tree.handcode.h
 cool-tree.cc		  -> [course dir]/src/PA3/cool-tree.cc
 cool-tree.aps		  -> [course dir]/src/PA3/cool-tree.aps
 dumptype.cc		  -> [course dir]/src/PA3/dumptype.cc
 handle_flags.c           -> [course dir]/src/PA3/handle_flags.cc
 parser-phase.cc	  -> [course dir]/src/PA3/parser-phase.cc
 stringtab.cc		  -> [course dir]/src/PA3/stringtab.cc
 tokens-lex.cc		  -> [course dir]/src/PA3/tokens-lex.cc
 tree.cc		  -> [course dir]/src/PA3/tree.cc
 utilities.cc		  -> [course dir]/src/PA3/utilities.cc
 *.d			  dependency files
 *.*			  other generated files

The include (.h) files for this assignment can be found in 
[course dir]/include/PA3

	The Makefile contains targets for compiling and running your
	program. DO NOT MODIFY.
    
	The README contains this info. Part of the assignment is to
	fill in the README with the write-up for your project. You should
	explain design decisions, explain why your code is correct, and why
	your test cases are adequate. It is part of the assignment to
	clearly and concisely explain things in text as well as to comment
	your code. Just edit this file.

	cool.y is the skeleton for the parser specification that you
	are to write. It already contains productions for the program
	and the classes. Use them as an example to write the remaining
	productions.  You should also read the bison documentation.
	This skeleton will compile and run as is, but it doesn't
	do much.

	good.cl, bad.cl test a few features of the grammar. You should
	add tests to ensure that good.cl exercises every legal
	construction of the grammar and that bad.cl exercises as many
	different parsing errors as you can squeeze into one file.

	cool-tree.aps contains the definitions for the tree language
	which you use to construct the abstract syntax tree (AST).
	From this file, cool-tree.h and cool-tree.cc are automatically 
        generated by a utility that compiles the specification into
        C++ functions for producing and consuming the tree nodes.
        This file is provided for your reference.  DO NOT MODIFY.

        tree.{cc|h} contain definitions used by the tree package.
        cool-tree.handcode.h is the handwritten extension to
        cool-tree.h.  If you read cool-tree.h and cool-tree.cc, you will
        note that there are "hooks" for extending the classes
        declarations.  Extending and modifying the tree package is
        discussed in the "Cool Tour", but you do not need to (and should
        not) modify the tree package for this assignment.

	tokens-lex.cc is a lexer capable of reading a token stream from
	console in the format produced by the lexer phase. DO NOT
	MODIFY.

        parser-phase.cc contains a driver to test the parser. DO NOT
        MODIFY.

	dumptype.cc prints the AST out in a form readable by the
	semant phase of the compiler. DO NOT MODIFY.

	handle_flags.cc implements routines for parsing command line
        flags. DO NOT MODIFY.

        The rest of the files are created as byproducts of `bison'.
        `cool-parse.cc' is the generated C++ file containing the
        parser.

	Files not discussed are covered in the README for PA2.

Instructions
------------

	To compile your parser program type:

	% make parser

	This produces an executable named "parser" which is standalone
	phase of the Cool compiler.  It requires lexer, semant, and cgen
	to do anything useful.

	To test your parser on a file 'foo.cl' type

	% myparser foo.cl

	myparser is a shell script that "glues" together lexer and
	parser using pipes.

	To run your parser on the files good.cl and bad.cl type:

	% make dotest

	If you think your parser is correct and behaves like
	the one we wrote, you may want to run a COOL compiler using
	your parser:

	% mycoolc foo.cl

	To overwrite the default lexical analyzer with yours, replace 
	lexer (which is a symbolic link to the "official" lexer) with
        your lexer from PA2.

	Zip up the files cool.y, good.cl, bad.cl, good.output, bad.output
	and README. Don't forget to edit the README file to include your 
	write-up, and to write your own test cases in good.cl and bad.cl.
	Submit your zip file through Canvas.

	GOOD LUCK!

---8<------8<------8<------8<---cut here---8<------8<------8<------8<---

Write-up for PA3
----------------
I believe that my code is near-equivalent to the stock parser. My tests
in good.cl show that my code accurately parses all of the different types
of constructs in the COOL language, and bad.cl shows that it meets requirements
for recovery from errors in parsing.

My general methodology in implementing lists of some construct (whether it be
features, expressions, etc) was to implement specific construct_list
non-terminals that would allow zero or more of that construct, and handle the
appropriate delimiting punctuation. These lists allowed me to help the parser
recover from errors within those lists and allow any number 0+ of the construct.

For constructs that could be empty or non-empty, I created a "non_empty_constr_list"
nonterminal. This helped resolve some shift/reduce conflicts and is a better way to
implement it than by putting empty and non-empty lists in one non-terminal, as once
a list is non-empty, it should not have any empty members in it.

I used precedence to resolve the shift-reduce conflicts in my LET statements. By
specifying within each let_stmt that it had left precedence and using right recursion,
my grammar does allow for nested LET statements. The rest of my precedence rules
come straight from the COOL manual. My other, more basic non-terminal and terminal
definitions in the grammar, are also taken straight from the manual (and put in
bison syntax.)


----good.cl----
I believe that good.cl uses all of the valid types of constucts in COOL
(that we were required to implement) in some way. My first class has
multiple methods, which test the ability of a class to have multiple
features. Its first feature, main(), uses a block and all of the basic types
of expressions. Its second feature, read_input(), is slightly modified from
the graph.cl example and tests a nested LET statement. In order for the
nested LET statements to work, a single LET statement must work, so this
adequately tests both of those cases. The second LET statement also uses
multiple "ID : TYPE"'s, which tests that my let_stmts code in cool.y works
properly. The body of the let statement also uses a while loop, verifying
that it works properly. Within the loop, there are calls to dispatches such
as "in_string()", verifying that a dispatch with an implied "self" works.
It also tests dispatches with a parameter and a dispatch without the
implied self.

The second class tests that inheritance is handled correctly, and tests 
the other types of features that I didn't use in class A, namely a feature
without an expression body, a feature that takes multiple parameters, and
one more that only takes one parameter.
My code within the class tests an IF statement, as well as a static dispatch.

The third class simply checks the other type of class that I had not yet
tested; namely one without any features.


----bad.cl----
bad.cl demonstrates that my parser catches many errors and recovers from
errors in a block, feature, let, or class and moves on to the next one.
The opening section shows how my code detects badly-formed expressions
and recovers, as well as badly formed features. It then recovers from 
an error in a let statement.
bad.cl goes on to demonstrate various types of class errors that exist,
and one more error later on to show that the parser was able to recover from
the previous errors and continue to find errors.



Problems:
One problem I ran into in trying to make my parser equivalent to
the correct parser was getting line numbers to line up properly.
I found that in the correct parser, every node that referred to
an instance of "no_expr" had a line number of 0. I wanted to use
this, but attempting to use SET_NODELOC(0) on each production that
used no_expr() resulted in the parent of the no_expr node also
having its node location set to 0. As of right now, I have not been
able to resolve this issue. This should only appear in a feature
or in a "let", as those are the only parts of my code that call
no_expr().
